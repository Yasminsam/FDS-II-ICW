# FDS-II-ICW
The purpose of this implementation is to compare the speed and accuracy of first and second order optimisation algorithms. Since the code
https://github.com/sanghvirajit/Feedforward_Neural_Network
Only the implementation of first-order methods was considered, the necessary changes to calculate Newton's second-order method were added to it. 
Comparison of speed and accuracy of first-order optimization methods such as gradient descent - Adam - Adamax - RMSprop by Newton method.
This test was performed on the MNIST dataset. The model used in this test has two layers of dense . Thanks to Sangh Virajit.
